{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031a7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from time import sleep\n",
    "import json\n",
    "\n",
    "\n",
    "# constant values.\n",
    "BASE_URL = \"https://api.genius.com\"\n",
    "CLIENT_ACCESS_TOKEN = \"ENTER YOUR API KEY HERE\"\n",
    "ARTIST_NAME = \"Sopico\"\n",
    "#ENTER THE NAME OF THE ARTIST HERE, AS IT IS WRITTEN ON THE GENIUS PAGE UNDER THE PROFILE PICTURE\n",
    "\n",
    "# send request and get response in json format.\n",
    "def _get(path,params=None, headers=None):\n",
    "\n",
    "    # generate request URL\n",
    "    requrl = '/'.join([BASE_URL,path])\n",
    "    token = \"Bearer {}\".format(CLIENT_ACCESS_TOKEN)\n",
    "    if headers:\n",
    "        headers['Authorization'] = token\n",
    "    else:\n",
    "        headers = {\"Authorization\": token}\n",
    "\n",
    "    response = requests.get(url=requrl, params=params, headers=headers)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_artist_songs(artist_id):\n",
    "    current_page = 1\n",
    "    next_page = True\n",
    "    songs = []\n",
    "\n",
    "    # main loop\n",
    "    while next_page:\n",
    "\n",
    "        path = \"artists/{}/songs/\".format(artist_id)\n",
    "        params = {'page': current_page}\n",
    "        data = _get(path=path, params=params)\n",
    "\n",
    "        page_songs = data['response']['songs']\n",
    "\n",
    "        if page_songs:\n",
    "            # add all the songs of current page,\n",
    "            # and increment current_page value for next loop.\n",
    "            songs += page_songs\n",
    "            current_page += 1\n",
    "        else:\n",
    "            # if page_songs is empty, quit.\n",
    "            next_page = False\n",
    "\n",
    "    # get all the song ids, excluding not-primary-artist songs.\n",
    "    songs = [song[\"id\"] for song in songs\n",
    "             if song[\"primary_artist\"][\"id\"] == artist_id]\n",
    "\n",
    "    return songs\n",
    "\n",
    "def get_song_information(song_ids):\n",
    "    song_list = {}\n",
    "\n",
    "    # main loop\n",
    "    for i, song_id in enumerate(song_ids):\n",
    "        print(\"id:\" + str(song_id) + \" start. ->\")\n",
    "\n",
    "        path = \"songs/{}\".format(song_id)\n",
    "        data = _get(path=path)[\"response\"][\"song\"]\n",
    "\n",
    "        song_list.update({\n",
    "        i: {\n",
    "            \"title\": data[\"title\"],\n",
    "            \"album\": data[\"album\"][\"name\"] if data[\"album\"] else \"<single>\",\n",
    "            \"release_date\": data[\"release_date\"] if data[\"release_date\"] else \"unidentified\",\n",
    "            \"featured_artists\":\n",
    "                [feat[\"name\"] if data[\"featured_artists\"] else \"\" for feat in data[\"featured_artists\"]],\n",
    "            \"producer_artists\":\n",
    "                [feat[\"name\"] if data[\"producer_artists\"] else \"\" for feat in data[\"producer_artists\"]],\n",
    "            \"writer_artists\":\n",
    "                [feat[\"name\"] if data[\"writer_artists\"] else \"\" for feat in data[\"writer_artists\"]],\n",
    "            \"genius_track_id\": song_id,\n",
    "            \"genius_album_id\": data[\"album\"][\"id\"] if data[\"album\"] else \"none\",\n",
    "            \"image_url\" : data[\"song_art_image_url\"]}\n",
    "        })\n",
    "\n",
    "        print(\"-> id:\" + str(song_id) + \" is finished. \\n\")\n",
    "    return song_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Searching \" + ARTIST_NAME + \"'s artist id. \\n\")\n",
    "\n",
    "# find artist id\n",
    "find_id = _get(\"search\", {'q': ARTIST_NAME})\n",
    "for hit in find_id[\"response\"][\"hits\"]:\n",
    "   if hit[\"result\"][\"primary_artist\"][\"name\"] == ARTIST_NAME:\n",
    "       artist_id = hit[\"result\"][\"primary_artist\"][\"id\"]\n",
    "       break\n",
    "\n",
    "print(\"-> \" + ARTIST_NAME + \"'s id is \" + str(artist_id) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c2e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-> \" + ARTIST_NAME + \"'s id is \" + str(artist_id) + \"\\n\")\n",
    "\n",
    "print(\"getting song ids. \\n\")\n",
    "\n",
    "# get all song ids and make a list.\n",
    "song_ids = get_artist_songs(artist_id)\n",
    "print(song_ids)\n",
    "\n",
    "print(\"getting meta data of each song. \\n\")\n",
    "\n",
    "# finally, make a full list of songs with meta data.\n",
    "full_list_of_songs = get_song_information(song_ids)\n",
    "\n",
    "print(\"-> Finished! Dump the data into json data. \\n\")\n",
    "\n",
    "with open(\"./\" + ARTIST_NAME + \"Songs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(full_list_of_songs, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"-> Mission complete! Check it out!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9def71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the JSON file with UTF-8 encoding\n",
    "with open(f\"{ARTIST_NAME}Songs.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caff5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a set to store unique album IDs\n",
    "album_ids = set()\n",
    "album_name = set()\n",
    "\n",
    "# Iterate through the keys in the dictionary (0, 1, 2, etc.)\n",
    "for key in data:\n",
    "    song = data[key]\n",
    "    if \"genius_album_id\" in song:\n",
    "        album_ids.add(song[\"genius_album_id\"])\n",
    "    if \"album\" in song:\n",
    "        album_name.add(song[\"album\"])\n",
    "    \n",
    "# Count the number of unique album IDs\n",
    "num_unique_albums = len(album_ids)\n",
    "\n",
    "print(f\"There are {num_unique_albums} different album IDs in the JSON file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f905a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(album_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fcd884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store albums, their tracks, and track IDs\n",
    "albums_dict_with_ids = {}\n",
    "\n",
    "# Iterate through the keys in the dictionary (0, 1, 2, etc.)\n",
    "for key in data:\n",
    "    song = data[key]\n",
    "    album_id = song.get(\"genius_album_id\")\n",
    "    title = song.get(\"title\")\n",
    "    track_id = song.get(\"genius_track_id\")\n",
    "\n",
    "    if album_id is not None:\n",
    "        # Check if the album ID already exists in the dictionary\n",
    "        if album_id not in albums_dict_with_ids:\n",
    "            albums_dict_with_ids[album_id] = {\"album_name\": song[\"album\"], \"tracks\": []}\n",
    "\n",
    "        # Append the song title and track ID to the album's \"tracks\" list\n",
    "        albums_dict_with_ids[album_id][\"tracks\"].append({\"title\": title, \"track_id\": track_id})\n",
    "\n",
    "# Save the album, track, and track ID data to a new JSON file\n",
    "with open(f\"{ARTIST_NAME}SongsWithIDs.json\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    json.dump(albums_dict_with_ids, output_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Albums, tracks, and track IDs data saved to {ARTIST_NAME}SongsWithIDs.json.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98898381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original JSON data\n",
    "with open(f\"{ARTIST_NAME}SongsWithIDs.json\", \"r\", encoding=\"utf-8\") as input_file:\n",
    "    original_data = json.load(input_file)\n",
    "\n",
    "\n",
    "min_songs_per_album = 6\n",
    "\n",
    "# Create a new dictionary to store filtered albums\n",
    "filtered_albums_dict = {}\n",
    "\n",
    "# Iterate through albums in the original dictionary\n",
    "for album_id, album_data in original_data.items():\n",
    "    num_tracks = len(album_data.get(\"tracks\", []))\n",
    "    # Check if the album has at least min_songs_per_album tracks\n",
    "    if num_tracks >= min_songs_per_album:\n",
    "        filtered_albums_dict[album_id] = album_data\n",
    "\n",
    "# Save the filtered album data to a new JSON file\n",
    "with open(f\"{ARTIST_NAME}SongsWithIDsFiltered.json\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    json.dump(filtered_albums_dict, output_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Albums with at least {min_songs_per_album} songs data saved to {ARTIST_NAME}SongsWithIDsFiltered.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f8eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "import re\n",
    "\n",
    "def transform_artist_name(input_string):\n",
    "    parts = input_string.split(\"'\")\n",
    "    if len(parts) > 1:\n",
    "        parts[1] = parts[1].lower()\n",
    "    cleaned_string = ''.join(parts)\n",
    "    return cleaned_string\n",
    "\n",
    "\n",
    "ARTIST_NAME_U = unidecode(ARTIST_NAME)\n",
    "ARTIST_NAME_U = transform_artist_name(ARTIST_NAME_U)\n",
    "print(ARTIST_NAME_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to scrape lyrics from Genius\n",
    "def scrape_lyrics(artist, track):\n",
    "    track = unidecode(track.lower().replace(' ', '-'))\n",
    "    track = track.replace(\"'\",\"\")\n",
    "    track = track.replace(\"(\",\"\")\n",
    "    track = track.replace(\")\",\"\")\n",
    "    track = track.replace(\":\",\"-\")\n",
    "    track = track.replace(\"[\",\"\")\n",
    "    track = track.replace(\"]\",\"\")\n",
    "    track = track.replace(\",\",\"\")\n",
    "    track = track.replace(\"+\",\"\")\n",
    "    track = track.replace(\"%\",\"\")\n",
    "    track = track.replace(\"#\",\"\")\n",
    "    \n",
    "    search_url = f\"https://genius.com/{artist.replace(' ', '-')}-{track}-lyrics\"\n",
    "    try:\n",
    "        response = requests.get(search_url)\n",
    "        print(\"track's lyrics found\")\n",
    "        if response.status_code == 404:\n",
    "            print(f\"Lyrics not found for {track} by {artist}.\")\n",
    "            print(search_url)\n",
    "            return None\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        lyrics_div = soup.find('div', class_='Lyrics__Container-sc-1ynbvzw-1 kUgSbL')\n",
    "        if lyrics_div:\n",
    "            lyrics = lyrics_div.get_text('\\n')\n",
    "            return lyrics.strip()\n",
    "    except requests.ConnectionError:\n",
    "        print(f\"Connection error for {track} by {artist}. Skipping the track.\")\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "# Open the JSON file with UTF-8 encoding\n",
    "with open(f\"{ARTIST_NAME}SongsWithIDsFiltered.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Iterate through the data and add lyrics to each track\n",
    "for album_id, album_data in data.items():\n",
    "    tracks = album_data[\"tracks\"]\n",
    "    for track_info in tracks:\n",
    "        track_name = track_info[\"title\"]\n",
    "        lyrics = scrape_lyrics(ARTIST_NAME_U, track_name)  \n",
    "        if lyrics is not None:\n",
    "            track_info[\"lyrics\"] = lyrics\n",
    "\n",
    "# Save the updated data to a new JSON file while keeping it sorted by album\n",
    "with open(f\"{ARTIST_NAME}SongsWithLyricsSorted.json\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    json.dump(data, output_file, indent=4, ensure_ascii=False, sort_keys=True)\n",
    "\n",
    "print(f\"Lyrics added and data saved to '{ARTIST_NAME}SongsWithLyricsSorted.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0835bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "with open(f\"{ARTIST_NAME}Songs.json\", \"r\", encoding=\"utf-8\") as songs_file:\n",
    "    songs_data = json.load(songs_file)\n",
    "\n",
    "# Load data wiht lyrics\n",
    "with open(f\"{ARTIST_NAME}SongsWithLyricsSorted.json\", \"r\", encoding=\"utf-8\") as lyrics_file:\n",
    "    lyrics_data = json.load(lyrics_file)\n",
    "\n",
    "# Create a CSV file for the combined data\n",
    "with open(f\"{ARTIST_NAME}SongsCombined.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    fieldnames = [\"Song Name\", \"Song ID\", \"Album Name\", \"Album ID\", \"Release Date\", \"Lyrics\",\"url\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    \n",
    "    # Write the CSV header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Iterate through the data and match song names and album IDs\n",
    "    for song_id, song_info in songs_data.items():\n",
    "        song_name = song_info[\"title\"]\n",
    "        album_name = song_info[\"album\"]\n",
    "        release_date = song_info[\"release_date\"]\n",
    "        album_id = None  # Initialize album_id as None\n",
    "        lyrics = \"\"  # Initialize lyrics as an empty string\n",
    "        url = song_info[\"image_url\"]\n",
    "        \n",
    "        # Search for the matching album in the lyrics data\n",
    "        for lyr_album_id, lyr_album_info in lyrics_data.items():\n",
    "            if lyr_album_info[\"album_name\"] == album_name:\n",
    "                album_id = lyr_album_id  # Match found, set the album_id\n",
    "                break\n",
    "        \n",
    "        # Check if album_id is not None and song_name is in the track titles\n",
    "        if album_id is not None:\n",
    "            album_tracks = lyrics_data[album_id][\"tracks\"]\n",
    "            for track in album_tracks:\n",
    "                if track[\"title\"] == song_name and \"lyrics\" in track:\n",
    "                    lyrics = track[\"lyrics\"]\n",
    "                    break\n",
    "                \n",
    "        # Write the data to the CSV file\n",
    "        writer.writerow({\n",
    "            \"Song Name\": song_name,\n",
    "            \"Song ID\": song_info[\"genius_track_id\"],\n",
    "            \"Album Name\": album_name,\n",
    "            \"Album ID\": album_id,\n",
    "            \"Release Date\": release_date,\n",
    "            \"Lyrics\": lyrics,\n",
    "            \"url\":url\n",
    "        })\n",
    "\n",
    "print(f\"CSV file '{ARTIST_NAME}SongsCombined.csv' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "df = pd.read_csv(f\"{ARTIST_NAME}SongsCombined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9865c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36299912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6100cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where the \"Lyrics\" column is not NaN and when the album has an ID\n",
    "df1 = df[(~df[\"Lyrics\"].isna() & (df[\"Album ID\"] != \"none\"))]\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the filtered DataFrame back to a CSV file\n",
    "df1.to_csv(f\"{ARTIST_NAME}SongsFiltered.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Filtered CSV file '{ARTIST_NAME}SongsFiltered.csv' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ccfe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop_duplicates(subset = ['Song Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a979ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ef863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def text_cleansing(data):\n",
    "    '''Removes brackets, replaces new line breaks with spaces, \n",
    "    lowercases everything, removes punctuations, extra whitespaces, and break words'''\n",
    "    data = data.str.replace(\"[\\(\\[].*?[\\)\\]]\", '')\n",
    "    data = data.str.replace(\"\\n\", ' ')\n",
    "    data = data.str.lower()\n",
    "    data = data.str.replace('[{}]'.format(string.punctuation), '')\n",
    "    return data\n",
    "\n",
    "df1.loc[:,'rem_sp_char'] = text_cleansing(df1.loc[:,'Lyrics'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8442ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409bed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_stopwords(text):   \n",
    "    clean_text = list()\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    words=[\"ouai\",\"oui\",\"no\",\"nan\",\"non\",\"jsais\",\"ca\",\"ça\",\"jai\",\"cest\",\"jsuis\",\"si\",\"jme\",\"tas\",\"ni\",\"jte\",\"ya\",\"eh\",\"oh\",\"comme\",\"plus\",\"tant\",\"plus\",\"rien\",\"tout\",\"quand\",\"ouais\",\"ouai\",\"trop\",\"là\",\"va\",\"dla\",\"où\",\"san\",\"quon\",\"quil\",\"quelle\"\n",
    "          \"qujdois\",\"davoir\",\"skandalize\",\"dun\",\"sen\",\"car\",\"faire\",\"fais\",\"jirai\",\"quelle\",\"faut\",\n",
    "          \"ai\", \"as\", \"a\", \"avons\", \"avez\", \"ont\",\"suis\", \"es\", \"est\", \"sommes\", \"êtes\", \"sont\",\"fais\", \"fais\", \"fait\", \"faisons\", \"faites\", \"font\",\n",
    "          \"peux\", \"peut\", \"pouvons\", \"pouvez\", \"peuvent\",\"dois\", \"dois\",\"cette\",\"tous\",\"doit\",\"jveux\",\"jmets\",\"devons\",\"jfais\",\"yeah\",\"devez\", \"doivent\", \"vais\", \"vas\", \"va\", \"allons\", \"allez\", \"vont\",\"estce\",\"dit\",\"quelque\",\"jetais\"]\n",
    "    ignore= (stopwords.words('french') + words)\n",
    "    \n",
    "    for i in text:\n",
    "        words = nltk.word_tokenize(i)\n",
    "        for element in ignore: \n",
    "            words = list(filter(lambda x: x!= element and len(x) > 1, words))\n",
    "        lyric = \" \".join(words)\n",
    "        clean_text.append(lyric)\n",
    "    \n",
    "    return clean_text\n",
    "        \n",
    "df1['LyricsClean'] = remove_stopwords(df1['rem_sp_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70f2f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install colorthief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9053799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2hex(r,g,b):\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(r,g,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa0db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from colorthief import ColorThief\n",
    "import matplotlib.backends.backend_pdf as pdf_backend\n",
    "\n",
    "# Function to create a word cloud and frequency graph for a given album\n",
    "def create_wordcloud_and_frequency_graph(text, album_name, album_cover_url, pdf):\n",
    "    # Create a word cloud\n",
    "    # Fetch the album cover image from the URL\n",
    "    album_cover = Image.open(requests.get(album_cover_url, stream=True).raw).convert('RGB')\n",
    "    color_thief = ColorThief(requests.get(album_cover_url, stream=True).raw)\n",
    "    dominant_color = color_thief.get_color(quality=1)\n",
    "    dominant_color = rgb2hex(dominant_color[0],dominant_color[1],dominant_color[2])\n",
    "    mask = np.array(album_cover)\n",
    "    image_colors = ImageColorGenerator(mask)\n",
    "    wordcloud = WordCloud(width=400, height=400, background_color=\"white\", mask=mask,collocations =False).generate(text)\n",
    "    \n",
    "    # Calculate word frequencies\n",
    "    word_counts = Counter(text.split())\n",
    "    most_common_words = word_counts.most_common(15)\n",
    "    words, counts = zip(*most_common_words)\n",
    "    \n",
    "    \n",
    "    # Create a bar chart for word frequencies\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(mask, cmap=plt.cm.gray, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Album Cover for {album_name}\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Word Cloud for {album_name}\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.barh(words, counts, color=dominant_color)\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.title(f\"Top 15 Most Frequent Words for {album_name}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "with pdf_backend.PdfPages(f'wordcloud_plots_{ARTIST_NAME_U}.pdf') as pdf:\n",
    "    for album_name, group in df1.groupby(\"Album Name\"):\n",
    "        lyrics = \" \".join(group[\"LyricsClean\"])\n",
    "        album_cover_url = group[\"url\"].iloc[0] \n",
    "        create_wordcloud_and_frequency_graph(lyrics, album_name, album_cover_url, pdf)\n",
    "        print(\"This album's analysis is done\")\n",
    "print(\"PDF generated !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
